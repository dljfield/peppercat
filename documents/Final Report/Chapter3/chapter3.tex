\chapter{Implementation}INTRODUCTION GOES HERE\section{Renderer}The graphics renderer was the first piece of the game engine worked on. Having the graphics to provide a view into the game world was important in order to easily see whether things were behaving as expected and proved extremely useful in detecting problems with other parts of the game later on.This section will go over firstly what isometric projection is and then the ways that graphics are actually drawn to the screen. Finally, the difficulties that the renderer caused during implementation will be discussed.\subsection{Isometric Tiles}\subsubsection{What Is Isometric?}When talking about isometric projection in the videogame world it is important to know that it is not truly isometric. True isometric is an ``axonometric projection in which the three coordinate axes appear equally foreshortened and the angles between any two of them are 120 degrees'' \todo{reference}. What the gaming world calls `isometric' is in fact \textit{dimetric} projection \todo{reference}---a projection where two axes are the same but the third is not.The reasons for doing this are essentially one of aesthetics when drawing objects at a very low resolution with visible pixels. At these very coarse resolutions, true isometric projection creates an aesthetically displeasing line. However, by changing to a dimetric projection, where the line grows twice as fast horizontally as it does vertically, the line becomes much more consistent and visually appealing. \todo{figure}\subsubsection{Cartesian To Isometric}The term ``\textsc{2d} isometric tile'' used in this report is a little ambiguous. The game world itself is represented by simple \textsc{2d} Cartesian coordinates that map to a grid of tiles. Isometric space, however, is \textsc{3d}. The term used here refers to the type of graphic used to represent the tiles in isometric space, rather than the isometric space itself. These graphics are simple \textsc{2d} images, drawn in such a way as to make them look \textsc{3d}. \todo{figure showing cartesian and isometric}Of course, this means that a conversion has to be made between the two coordinate systems in order for the renderer to be able to display things in their proper place. As an example, figure \todo{figure} shows what the game world looks like if it is rendered without this coordinate conversion---clearly very wrong.In order for the renderer to show things correctly in the isometric space there needs to be a way of converting between the game world's Cartesian coordinates and the renderer's isometric coordinates. Luckily, this is incredibly simple:\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={JavaScript implementation of a function to turn Cartesian coordinates into game isometric coordinates. Original algorithm from \cite{citeulike:13155325}.}, label=cartesian_to_isometric]function cartesianToIsometric(cartesian_x, cartesian_y){	var isometric = {};    isometric.x = cartesian_x - cartesian_y;    isometric.y = (cartesian_x + cartesian_y) / 2;    return isometric;}\end{lstlisting}\end{minipage}Now when the renderer draws the game to the \textsc{html5} canvas, it can first call the \texttt{cartesianToIsometric} function, letting it place the tile graphics in the correct place as seen in figure \todo{figure}.\subsection{Rendering}After the renderer has converted between Cartesian and isometric spaces it needs to be able to draw things to the canvas. The actual drawing of a game tile to the canvas is straightforward, simply requiring a call to the canvas's \texttt{drawImage()} function and supplying it the image you wish to draw and the canvas coordinates for where you wish it to be drawn.The difficult part comes before that. Firstly, you need to be able to work out what the canvas coordinates are. The conversion between isometric coordinates and the canvas coordinates works as follows:\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={Conversion between isometric coordinates and canvas coordinates.}, label=isometric_to_canvas]canvas_x = isoCoords.x * (TILE_WIDTH / 2);canvas_y = isoCoords.y * (TILE_HEIGHT / 2) - (image_height - (TILE_HEIGHT / 2));\end{lstlisting}\end{minipage}A few things should be explained about this. Firstly, \texttt{TILE\_WIDTH} and \texttt{TILE\_HEIGHT} refer to the set size of a single tile and are used to work out the tile's positioning in the world. The \texttt{image\_height} value refers to how tall in pixels an image is. Theoretically an image can have any size and isn't limited to how large a tile is. However, in practical terms, an image can only be arbitrarily tall; width needs to be kept within the tile limits or there will be problems with depth sorting, for reasons seen in section \ref{entity_rendering}.\todo{a figure showing the difference between a tile and the image representing it}Also worth noting is that there are separate rendering functions used for the terrain and the entities. The terrain has no height value, but even if it did it is rendered in such a way as to make it irrelevant, so the drawing of terrain tiles excludes the \texttt{image\_height} part of the calculation.Once you have the coordinates you then need to get the tile graphic to use as the image being rendered. Getting the image itself is a very simple task, but getting the order in which to draw them right is more difficult.The \textsc{html5} canvas is a very simple element and it has no ability to specify the relative depth of things being drawn to it; whatever is drawn first will be occluded by what comes afterwards if they overlap. This overlapping is often not a problem when drawing simple \textsc{2d} tiles with a top-down or side-on perspective. However, because the isometric perspective is \textsc{3d} the issue of depth becomes an important one.\todo{Figure of what it looks like when depth sorting is broken}There are two methods for solving this used in the renderer: a simple painter's algorithm and a depth sorting algorithm. The first is used for the terrain and the second for entities.\subsubsection{Terrain Rendering}The terrain is very simple to render as far as isometric projection goes. Terrain images are the same size as the tiles, which means that as long as they are drawn in order the images will never overlap.The method for achieving this ordering is known as a painter's algorithm\footnote{The painter's algorithm is so called because of a common painting technique whereby distant parts are painted before closer parts that might cover them.} and is very simple. Firstly, all the terrain is stored in a pre-sorted, two dimensional array. Columns are labelled \texttt{y} and rows are labelled \texttt{x}. Images are drawn by looping through each row in each column and drawing them one by one, rendering the images from back to front, row by row.\todo{Diagram showing how the painter's algorithm works}This is a very efficient and cheap way to render the images to the screen, and works perfectly for the terrain. Even if the terrain were to be made no longer flat, as long as it never broke out of the tile grid there would be no need to change how it is rendered.\subsubsection{Entity Rendering}\label{entity_rendering}Unfortunately, entities are less easy to deal with. At least some entities can move around---crossing tile boundaries when they do so---which means they cannot be stored in the same grid that makes up the tiles themselves. Because entities can exist outside of the tile boundaries, working out their depth cannot be done just by iterating through them like the terrain. Another way has to be devised in order to render them in the correct order.To figure out the order that entities need to be rendered it is first necessary to work out what their relative depth in the scene is. To get an entity's depth, the following calculation is used:\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={Calculation to work out an entity's relative depth in the scene.}, label=calculate_depth]function calculateDepth(entity) {    return Math.round((entity.x * TILE_WIDTH / 2) + (entity.y * TILE_HEIGHT / 2) + entity.z);}\end{lstlisting}\end{minipage}In this calculation, the most important part is the addition of an entity's position data, \texttt{x}, \texttt{y} and \texttt{z}. The \texttt{z} attribute is not currently used in the game, but if it were it would represent relative height from the ground plane and is thus important to the depth calculation. The use of the \texttt{TILE\_HEIGHT} and \texttt{TILE\_WIDTH} attributes is due to the small values of the position data. Because tiles can potentially have small values like \texttt{(1, 1)}---though they could also in theory be very large---it is often common for depth values to be worked out as being the same. Multiple entities sharing a depth value will often cause them to be rendered in the wrong order. The other issue is that positions can be non-integer, such as \texttt{(1.250, 1)}. The sorting method used can't handle this, so it's necessary to round to a whole number in order to make sure it doesn't break.The sorting method itself is a modified pigeonhole sort, as shown in Listing \ref{depth_sort}.\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={Depth sorting entities in a scene using a modified pigeonhole sort.}, label=depth_sort]function depthSort(entities) {    var buckets = [];    for (entity in entities) {        var depth = this.calculateDepth(entities[entity]);        if (!buckets[depth])            buckets[depth] = [];        buckets[depth].push(entities[entity]);    }    var result = [];    for (bucket in buckets) {        for (entity in buckets[bucket]) {            result.push(buckets[bucket][entity]);        }    }    return result;}\end{lstlisting}\end{minipage}The pigeonhole sort works well for this task. The first reason for this is that the number of entities and number of keys are almost always the same, and even when not the smaller number of keys does not affect the performance of the sort. The number of entities being placed into the sort is also usually very small, which means that memory is not a concern, though with a very large number of entities the memory footprint could be a problem. The other reason the pigeonhole sort works well is that it keeps intact the link between a depth value and the entity it represents without any extra work. This means that the sorted array containing the entities can be used directly in the renderer, saving development and processor time.The sorted array that comes out of the pigeonhole sort is flat, so the renderer only needs to loop through it once in order to render all the entities to the canvas at the correct depth.\subsubsection{Depth Sorting Limitations}The depth sorting used in the project works well and performs as expected. However, it has a major limitation in that it will not work for entities that can exist across multiple tiles. Currently, all entities are the size of a single tile---though they may have arbitrary height within it. This makes calculating the depth a simple case of looking at position. If an entity were to be larger than a single tile, however, the position data would not be sufficient to determine depth.There are two ways to have entities that can exist across multiple tiles. The first is to have the entities be actually made up of multiple tiles. There are two frustrations with this. The first is that artwork needs to be split up into multiple tiles, which means that content in the game is harder to create. The second is that entities need to keep track of what tiles they are taking up, creating further work for the sorting algorithm to do in order to figure out what is where and gaining little over simply having lots of separate entities pushed together to appear whole.The better option here is to keep a model of an entity's position in \textsc{3d} space. Although the entities themselves are rendered with \textsc{2d} images, because of the isometric projection they still exist in \textsc{3d} space. By keeping data that models this three dimensionality it is possible to work out the depth of an entity without associating it with more than one tile. Instead, it is given a central tile and the data about its size fills out the rest of it.This approach affects more than just the rendering. By having an actual size in \textsc{3d} space entities can be interacted with in a more fine-grained way. For example, the current system of collision detection simply checks to see whether a tile position contains an entity or not. This is relatively simple to implement but it is not very versatile---position data is very coarse. By turning the game world into a \textsc{3d} simulation it is suddenly possible for position data to be more fine-grained. Not only can the renderer work out the depth of something that is not bound by whole tiles, collision detection is no longer bound by whole tiles either.Of course, doing this is very complicated and would require a complete rewrite of almost all of the game engine's underlying systems. Given the difficulties already encountered when implementing what was there it was decided that the huge effort involved was not worth it.\subsection{Renderer Implementation Difficulties}Being the first major feature to be worked on meant that the renderer was subject to a lot of change and iteration as the project developed. Things that appeared to be working fine at first turned out to be inadequate when other features were added. The renderer was probably the most rewritten and refactored part of the entire code base.The terrain has been the most stable part, with the rendering method being unchanged since it was first implemented. However, the entity rendering was changed a great deal. The initial implementation had the entities rendered in a way similar to the terrain, by placing them into an array at the correct locations and then iterating through it. While this technically worked, it was ugly and was soon found to be completely inadequate once entity movement was introduced to the game.The method for rendering entities including the depth sorting also did not work perfectly the first time either. At first the pigeonhole sort was not working properly, as entities were overwriting each other when they had the same depth value. This was solved by introducing the idea of buckets that could store multiple entities at once when they had the same depth value. The next step to solving this was to make sure that the depth values weren't so small. The depth values being taken only from the very small tile positions was causing them to often have the same depth value and unable to be sorted correctly as too many of them were being put into a bucket together. This was solved by adding the tile values to the calculation, which created much more variation in depth. It is now far rarer for entities to share a depth value, and when they do they do not overwrite each other.Beyond these specific problems, the renderer's place as first feature implemented also suffered from the lack of experience, in JavaScript, use of the \textsc{html5} canvas and games programming in general. A lot of time was spent researching and iterating on things that now would be much easier to implement and be done in a lot shorter time.\section{Input and Movement}Movement is one of the most important user facing features of the project. It also makes use of several parts of the game engine to work properly, relying on the game loop functioning correctly to advance the entity at the correct pace, the renderer to display this movement across tiles correctly and both the input manager and network manager to receive (and send) commands.\subsection{Input}The first and most important of these major parts is the input handler. Originally, the input handler was contained entirely in the \texttt{Engine} class. However, with the advent of the event manager it was refactored out into its own class.Input in the game is mouse-based, rather than keyboard-based. Being mouse-based, input is a little more difficult to handle than if it were possible to simply capture a button press. It is necessary to work out what location exactly the player has clicked, then go through a series of functions to turn the click location into game-world coordinates. Once the coordinates are known, they need to be checked for validity and then passed on, along with the event type, to any entities that might care to know about it.The first step in this is capturing the user's input. Browsers are helpful in that they keep track of where the user has clicked, which means that the browser event can be captured and used for the game's purposes. To listen for user clicks, a click event listener is attached to the game's canvas. Unfortunately, however, despite being attached to the canvas, the click event coordinates are global to the window, rather than being constrained by the canvas. What this means is that click coordinate \texttt{(0,0)} is not, in fact, the corner of the canvas, but instead the corner of the browser window that contains the canvas.To solve this, it is necessary to work out the click's position relative to the canvas. This is accomplished using the code in listing \ref{canvas_click_coordinates}.\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={Transforming a user's click to be relative to the canvas, rather than the window.}, label=canvas_click_coordinates]canvasPosition.x = ((event.clientX - this.engine.camera.x) - this.engine.canvas.offsetLeft) - (TILE_WIDTH / 2);canvasPosition.y = ((event.clientY - this.engine.camera.y) - this.engine.canvas.offsetTop);\end{lstlisting}\end{minipage}There are a few things to note in this code. First of all, the \texttt{event} used here is the one passed in from the click event listener, and is an object supplied by the browser. The next thing to note is the \texttt{camera} object. This is a game object that acts as the user's viewport into the world. Because the world can be bigger than the canvas itself, it is necessary to have a method of moving the view around the world, which is where the camera comes in. The camera object has an offset, which the renderer takes into account when positioning entities onto the canvas. Of course, this offset needs to be taken into account when detecting where, exactly, the user has clicked in the world, and so it is used here to do that. The coordinates are then set to be relative to the canvas instead of the window by using the \texttt{offsetLeft} and \texttt{offsetTop} values on the canvas itself, which refer to the canvas' position in the browser window.After this, a set of functions are used to first transform the canvas' isometric coordinates into \textsc{2d} Cartesian coordinates, and then from there to turn those into actual tiles, shown in Listing \ref{iso_cart_tile_coords}.\noindent\begin{minipage}{\linewidth}\begin{lstlisting}[style=js, caption={Turning the canvas isometric coordinates into \textsc{2d} Cartesian coordinates and then into tile positions. Original algorithm to transform isometric to Cartesian space from \cite{citeulike:13155325}.}, label=iso_cart_tile_coords]var cartCoords = (function(x, y){    var coords = {};    coords.x = (2 * y + x) / 2;    coords.y = (2 * y - x) / 2;    return coords;})(canvasPosition.x, canvasPosition.y);var tileCoords = (function(x, y){    var coords = {};    coords.x = Math.floor(x / (TILE_WIDTH / 2));    coords.y = Math.floor(y / (TILE_WIDTH  / 2));    return coords;})(cartCoords.x, cartCoords.y);\end{lstlisting}\end{minipage}With the tile coordinates acquired, they are sent into a method to work out what to do with them. It first checks for the validity of the tile coordinate by checking whether it is inside the bounds of the map. Assuming the coordinates are in bounds, a check is then done to see whether the player has clicked on an entity or whether they have clicked on a terrain tile. Clicking on an entity could mean either an invalid click location or a command to change to controlling that entity, depending on whether the user is the Game Master or not. However, clicking on a blank tile---and thus the terrain---always means a movement command.\subsection{Movement}There are two methods of giving an entity a movement command. The first is from the direct input as detailed in the previous section. The other is input from the network. These work similarly but not entirely the same.When handling input, all moveable entities are subscribed to events for both direct input and network input. Whether they do something with the direct or network input depends on the component they are using to handle it. For a player character, the direct input event is handled. For a remote character the network event is handled instead.\subsubsection{Direct Input}With the event processed, a series of other methods are called to move the entity. The first step is the pathing step, which makes use of the other changeable component in the \texttt{Character} class. For direct input, the entity needs to figure out the path it is going to take to move from its current position to the newly selected one. The first step here is to check whether or not the entity is currently following a path. If it is following a path then its location may not be a whole tile, which would cause the pathfinding algorithm to break. In cases where the entity is already following a path, it's next tile destination is used as the entity location instead of its current location.The pathfinding algorithm used is a library implementation of A*. This implementation provides what is known as the Manhattan style pathfinding, which does not allow diagonal movement. Although this is not the most efficient form of pathfinding, it was decided as being the best option for a variety of reasons. The first of these reasons is one of gameplay. With the tile-based nature of the game, diagonal movement feels somewhat odd. The second reason is one of artwork; in theory, having 8 directions of movement creates a need for extra animations and graphics for the players---although in reality no animation system was put in, nor were proper character graphics made.The final reason was to do with collision detection and rendering. Because of the way collision detection works, entities crossing each other diagonally actually end up intersecting with each other, which is an ugly graphical artefact. As was discussed in the previous section on graphics, the work needed to make this a non-issue is considerable and there is little reason to allow for diagonal movement anyway.The path returned from the A* algorithm is a series of tiles. To follow this path an entity first takes the next tile in the list and sets that as its destination. Whenever it reaches a destination, the path is checked again and a new destination selected. Once the path is completed there are no more destinations to get.To actually move towards a destination, the entity uses the \texttt{updatePostion} function, which performs a series of checks to determine the entity's current location compared to its destination. When the direction of movement is established, the entity's speed value is added to its position. This speed value is low, being just 0.125, taking eight frames to move an entire tile, though in theory adjusting the speed value would allow an entity to move fast or slower.Finally, an event is created to inform the server that the entity is going to move and to supply the path it is going to take to get to its destination.\subsubsection{Network Input}Movement of an entity that is not under the direct control of the client's player is very similar to moving one controlled through direct input. The difference is that when using network input an entity is given a path, rather than having to find the path for itself.It is important that a remote controlled entity does not find its own path because it is possible for that path to be different across different clients. Although the short distances available in the test map of the game showed that entities almost always take the same path regardless, in theory it is possible that by simply telling a remote entity to move to somewhere else the entity could end up taking a radically different path. As the game currently stands this isn't the biggest issue in the world. However, in a situation where full interaction with other entities was possible it could prove to be disastrous, as a client may see itself as unable to perform an action on an entity it should be allowed to affect, or vice versa.Currently, network input is simply taken from the client that created it and echoed by the server. Of course this is not ideal and in theory could produce terrible results due to malicious players. However, difficulties with the server implementation that are discussed in section \ref{server_implementation} will explain why it was done this way.\subsubsection{Without Input}Not every frame will have input from a player or the network. Despite this entities are still required to continue their movement. To deal with this each entity stores its current destination and its path as object variables. Every frame the \texttt{updateDestination} and \texttt{updatePostition} functions are called and make use of these variables. Regardless of whether there is input or not these two functions are called, and do nothing if there are no destinations to set or paths to follow.\section{The Server}\label{server_implementation}% The implementation should look at any issues you encountered as you tried to implement your design. During the work, you might have found that elements of your design were unnecessary or overly complex; perhaps third party libraries were available that simplified some of the functions that you intended to implement. If things were easier in some areas, then how did you adapt your project to take account of your findings?% It is more likely that things were more complex than you first thought. In particular, were there any problems or difficulties that you found during implementation that you had to address? Did such problems simply delay you or were they more significant?% You can conclude this section by reviewing the end of the implementation stage against the planned requirements.